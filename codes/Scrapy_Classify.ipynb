{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "postal-cambodia",
   "metadata": {},
   "source": [
    "# Library import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continuous-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "from threading import *\n",
    "import queue\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-discharge",
   "metadata": {},
   "source": [
    "# Target links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "elder-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=323000\n",
    "end = 327000\n",
    "link_list=[]\n",
    "for i in range(start,end):\n",
    "    link_list.append('http://www.newsmth.net/nForum/article/Intern/'+str(i)+'?ajax' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-confidence",
   "metadata": {},
   "source": [
    "# Scrapy Funtion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-administrator",
   "metadata": {},
   "source": [
    "## Process extends Thread Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supreme-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuimuSpider(Thread):\n",
    "    def __init__(self,url,q):\n",
    "        super(ShuimuSpider,self).__init__()\n",
    "        self.url=url\n",
    "        self.q=q\n",
    "        \n",
    "    def run(self):\n",
    "        self.parse_page()\n",
    "        \n",
    "    def send_request(self,url):\n",
    "        try:\n",
    "            html = requests.get(url,timeout=2)\n",
    "        except Exception as e:\n",
    "            print(\"fail at %s\" % url)\n",
    "        else:\n",
    "            return html\n",
    "    def parse_page(self):\n",
    "        response = self.send_request(self.url)\n",
    "        if response.status_code==200:\n",
    "            response_bs=response.content\n",
    "            try:\n",
    "                bs = BeautifulSoup(response_bs,'html.parser')\n",
    "\n",
    "\n",
    "                text=''\n",
    "                store_data={\n",
    "                    'time':[],\n",
    "                    'title':[],\n",
    "                    'detail':[]\n",
    "                }\n",
    "                text = bs.p.text\n",
    "                # .p 对应html中的<p>, 观察帖子不难发现，几乎所有的招聘正文都在帖子的<p>内\n",
    "                # .text 对应输出文本\n",
    "\n",
    "                #分别通过特殊字符串的位置给标题、时间、正文定位\n",
    "                #position for title:\n",
    "                Title_Position1=text.find('标  题: ')+len('标  题: ')\n",
    "                Title_Position2=text.find('  发信站: 水木社区')\n",
    "                Title = text[Title_Position1:Title_Position2]\n",
    "                #text[x:y]进行切片\n",
    "\n",
    "                #position for time:\n",
    "                Time_Position1=text.find('  发信站: 水木社区')+len('  发信站: 水木社区')\n",
    "                Time_Position2=text.find('), 站内')+1\n",
    "                Time=text[Time_Position1:Time_Position2]\n",
    "\n",
    "                #position for detail\n",
    "                Detail_Position1=text.find('), 站内')+len('), 站内')+4\n",
    "                Detail_Position2=text.find('※ 来源:·水木社区')\n",
    "                Detail=text[Detail_Position1:Detail_Position2]\n",
    "\n",
    "                store_data['time'].append(Time)\n",
    "                store_data['title'].append(Title)\n",
    "                store_data['detail'].append(Detail)\n",
    "                #字典赋值\n",
    "                #运行成功，index序列加一\n",
    "\n",
    "                self.q.put(store_data)\n",
    "            except:\n",
    "                return\n",
    "        else:\n",
    "            return\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-singapore",
   "metadata": {},
   "source": [
    "## Scrapy function with multi-threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twelve-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fast_Scrapy(x,y,store_data):\n",
    "    start = time.time()\n",
    "    q= queue.Queue(0)\n",
    "\n",
    "    Thread_list=[]\n",
    "    for url in link_list[x:y]:\n",
    "        p = ShuimuSpider(url,q)\n",
    "        p.start()\n",
    "        Thread_list.append(p)\n",
    "\n",
    "    for i in Thread_list:\n",
    "        i.join()\n",
    "\n",
    "    while not q.empty():\n",
    "        data = q.get()\n",
    "\n",
    "        store_data['time'].append(data['time'])\n",
    "        store_data['title'].append(data['title'])\n",
    "        store_data['detail'].append(data['detail'])\n",
    "    end = time.time()\n",
    "    print('当前Process + Queue多线程爬虫的总时间为：', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-cooking",
   "metadata": {},
   "source": [
    "## Scrapy RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "junior-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrapy():\n",
    "    store_data={\n",
    "        'time':[],\n",
    "        'title':[],\n",
    "        'detail':[]\n",
    "    }\n",
    "    if end-start>150:\n",
    "        period = np.arange(0,end-start,150)\n",
    "\n",
    "        for i in tqdm.tqdm(period):\n",
    "            Fast_Scrapy(i,i+150,store_data)\n",
    "        Fast_Scrapy(i,end,store_data)\n",
    "    else:\n",
    "        Fast_Scrapy(start,end,store_data)\n",
    "        \n",
    "    df = pd.DataFrame(store_data)\n",
    "    df.to_csv('../dataset/'+str(start)+'-'+str(end)+'.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efficient-cloud",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                                | 1/27 [00:04<01:46,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 4.093417406082153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████▏                                                                            | 2/27 [00:08<01:42,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 4.068395376205444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▏                                                                         | 3/27 [00:12<01:36,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.9336838722229004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▎                                                                      | 4/27 [00:16<01:32,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.9790713787078857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▎                                                                   | 5/27 [00:19<01:26,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.869795560836792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▍                                                                | 6/27 [00:23<01:23,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.9544966220855713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▌                                                             | 7/27 [00:27<01:18,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.8738880157470703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                          | 8/27 [00:31<01:14,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.8887741565704346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████▋                                                       | 9/27 [00:35<01:08,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.580000162124634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▎                                                   | 10/27 [00:39<01:04,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.785069465637207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▍                                                | 11/27 [00:42<01:00,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.818086624145508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████▍                                             | 12/27 [00:46<00:56,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.560930013656616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▍                                          | 13/27 [00:49<00:51,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.5114586353302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▌                                       | 14/27 [00:53<00:46,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.4503390789031982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▌                                    | 15/27 [00:56<00:43,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.54770565032959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████████▌                                 | 16/27 [01:00<00:39,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.5677502155303955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████▋                              | 17/27 [01:04<00:35,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.523587465286255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████▋                           | 18/27 [01:07<00:31,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.469503879547119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▋                        | 19/27 [01:11<00:28,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.642242431640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▋                     | 20/27 [01:15<00:25,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 4.046592950820923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████▊                  | 21/27 [01:19<00:22,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.8012423515319824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████▊               | 22/27 [01:22<00:18,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.7441470623016357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▊            | 23/27 [01:26<00:15,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 3.999932050704956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████████████████████████████████████████████████▉         | 24/27 [01:30<00:11,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 4.028943777084351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████████████▉      | 25/27 [01:35<00:08,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 4.314953088760376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▉   | 26/27 [01:39<00:04,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 4.091559886932373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [01:42<00:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 2.910522937774658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Process + Queue多线程爬虫的总时间为： 2.856959819793701\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = Scrapy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-workplace",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-forward",
   "metadata": {},
   "source": [
    "## Remove '[]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "descending-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove '[]'\n",
    "for col in ['time','title','detail']:\n",
    "    df[col]=df[col].apply(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-berlin",
   "metadata": {},
   "source": [
    "## Transfer to pd.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "higher-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer to pd.datetime\n",
    "df['time']=(df['time'].str[2:12]+df['time'].str[21:-1])\n",
    "df['time']=pd.to_datetime(df['time'],errors='coerce')\n",
    "df['time']=df['time'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-financing",
   "metadata": {},
   "source": [
    "## remove data with extremely short title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reflected-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['title'].str.len()>5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-commerce",
   "metadata": {},
   "source": [
    "## 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "british-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['title'].duplicated()]\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-sitting",
   "metadata": {},
   "source": [
    "## Remove datas without a delivering email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "indie-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}'\n",
    "regex = re.compile(pattern,flags=re.IGNORECASE)\n",
    "df['Email']='NaN'\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        df.iloc[i,3]=regex.findall(df['detail'][i])\n",
    "    except:\n",
    "        continue\n",
    "df.replace(to_replace='NaN',value = np.nan,regex=True,inplace =True)\n",
    "df.dropna(axis=0,how='any',inplace =True)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-classics",
   "metadata": {},
   "source": [
    "## output as text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ahead-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(df):\n",
    "    text=''\n",
    "    for i in range(len(df)):\n",
    "        text += str(df.index[i])+' '\n",
    "        text += df['title'][i]+'\\n'\n",
    "        text += df['detail'][i]+'\\n'\n",
    "        text += df['Email'][i]+'\\n\\n\\n'\n",
    "    \n",
    "    with open(str(start)+'-'+str(end)+'.txt','w',encoding='utf-8') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-discrimination",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-penguin",
   "metadata": {},
   "source": [
    "## Load Classify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "medical-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "clf_model=joblib.load('../models/Classification_model_5_n_estimator=100_pca=400.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-jacket",
   "metadata": {},
   "source": [
    "## Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "medium-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark = ['产品经理', '人力资源', '券商投行基金', '前端', '咨询', '外语实习生', '大数据', '投资实习生',\n",
    "       '数据分析', '数据挖掘', '测试工程师', '研发开发', '算法实习', '行业研究', '行政', '设计',\n",
    "       '财务会计审计税务', '运营实习', '量化交易', '销售']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "appropriate-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba_fast\n",
    "\n",
    "stopwords = pd.read_csv('../stopwords/baidu_stopwords.txt',\n",
    "                        quoting=3,sep='\\t',names=['stopword'],encoding='utf-8')\n",
    "stopwords = stopwords['stopword'].values\n",
    "\n",
    "def pre_input(input):\n",
    "    sentences=[]\n",
    "    segs=jieba_fast.cut(input,cut_all=False)\n",
    "    segs = list(filter(lambda x:x.strip(),segs))\n",
    "    segs=list(filter(lambda x:((x not in stopwords) and x != 'xa0' ),segs))\n",
    "    sentences.append(str([x for x in segs]))\n",
    "    return sentences\n",
    "\n",
    "def predict_df(x):\n",
    "    return mark[clf_model.predict(pre_input(x))[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-mailing",
   "metadata": {},
   "source": [
    "## predict for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "available-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category']=np.zeros(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "standard-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category']=df['detail'].apply(lambda x:predict_df(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "rocky-format",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>detail</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>用友网络科技股份有限公司法务部招收实习生</td>\n",
       "      <td>岗位职责：  1.起草、审核合同及各类法律文件，制定标准合同文本，参与与合同相关的业务设计、...</td>\n",
       "      <td>券商投行基金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【实习-汇安基金】量化实习生（有留用机会）</td>\n",
       "      <td>单位简介：  汇安基金管理有限责任公司，2016年4月19日获中国证监会批准，并在上海注册成...</td>\n",
       "      <td>券商投行基金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【实习】【上海】方正证券研究所金融工程组招聘量化实习生</td>\n",
       "      <td>【实习】【上海】方正证券研究所金融工程组招聘量化实习生  【工作职责】  1、协助开发资产配...</td>\n",
       "      <td>量化交易</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【招聘】中国新闻出版研究院</td>\n",
       "      <td>中国新闻出版研究院国际出版研究室  招聘小语种实习生    中国新闻出版研究院是我国唯一...</td>\n",
       "      <td>大数据</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【实习】【北京】悟语学堂招聘传播/推广岗-坐标骏豪中央公园</td>\n",
       "      <td>坐标：朝阳公园地铁边上骏豪中央公园  团队优势：弹性工作制、最火热最有价值的教育行业、行业大...</td>\n",
       "      <td>运营实习</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【微软】【北京】【实习】前端实习生</td>\n",
       "      <td>热爱前端开发的同学，可以投简历过来yanhu@microsoft.com  表现出色可以争取...</td>\n",
       "      <td>研发开发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【实习】【七鑫易维】 深度学习实习生</td>\n",
       "      <td>北京七鑫易维信息技术有限公司（www.7invensun.com）是致力于机器视觉和人工智...</td>\n",
       "      <td>算法实习</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【实习】【七鑫易维】 图像算法实习生</td>\n",
       "      <td>北京七鑫易维信息技术有限公司（www.7invensun.com）是致力于机器视觉和人工智...</td>\n",
       "      <td>算法实习</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【实习】【NVIDIA】英伟达2020实习季，期待你的加入！</td>\n",
       "      <td>又是一年校招季的结束，当2020届的同学已经找到心仪工作的同时，2021届的同学们是否也蠢蠢...</td>\n",
       "      <td>研发开发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>深圳Using.ai 招聘算法实习</td>\n",
       "      <td>关于我们    贝尔信息是一家具备优秀且可商业化的机器学习、视觉技术和一体式硬件研发能力的高...</td>\n",
       "      <td>算法实习</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【中国标准化研究院】招聘实习生</td>\n",
       "      <td>中国标准化研究院（初名国家科委标准化综合研究所）始建于1963年，是从事标准化研究的国家  ...</td>\n",
       "      <td>大数据</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【实习】【英特尔研究中心】计算机视觉/机器学习</td>\n",
       "      <td>简历请发送至：chenning.liu@intel.com          邮件标题：CV...</td>\n",
       "      <td>算法实习</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【兼职招聘】短视频视频剪辑 在校生也可以</td>\n",
       "      <td>【兼职招聘】短视频视频剪辑  会抖音小视频优先  自己或者朋友、亲戚家属，有擅长短视频制作的...</td>\n",
       "      <td>运营实习</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【百度实习】数据研发、数据挖掘工程师</td>\n",
       "      <td>团队介绍：拥有公司海量数据，专注于分析挖掘数据价值，通过数据平台和分析报告，助力产品线运营和...</td>\n",
       "      <td>研发开发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【快手】【行政数据实习生】</td>\n",
       "      <td>岗位职责：  1、负责协助行政项目的数据收集和整理；  2、负责对数据进行统计分析，根据数据...</td>\n",
       "      <td>大数据</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-11-27</td>\n",
       "      <td>【前海开源基金】人力资源实习生</td>\n",
       "      <td>【金牛基金公司-前海开源基金招聘】  岗位:人力资源实习生 base深圳  【岗位职责】  ...</td>\n",
       "      <td>券商投行基金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【快手】【公关实习生-数据分析方向】</td>\n",
       "      <td>公关实习生-数据分析方向  岗位描述：  1、根据需求进行数据挖掘和分析；  2、兼具发散思...</td>\n",
       "      <td>数据分析</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【快手】【公关实习生-短视频编辑方向】</td>\n",
       "      <td>公关实习生-短视频编辑  职位描述：  1、负责快手用户故事的策划和制作；  2、热爱人物短...</td>\n",
       "      <td>运营实习</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【实习】NLP算法、语音识别实习生【蓦然认知】</td>\n",
       "      <td>公司：北京蓦然认知科技有限公司  Base：北京  职位诱惑：AI独角兽潜力公司，薪资福利优...</td>\n",
       "      <td>算法实习</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>【快手】【部门助理实习生】</td>\n",
       "      <td>部门助理实习生  职位描述：  1、【部门事务支持】会议协调预定、办公用品管理、各类大小会议...</td>\n",
       "      <td>行政</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time                           title  \\\n",
       "20 2019-11-26            用友网络科技股份有限公司法务部招收实习生   \n",
       "21 2019-11-26           【实习-汇安基金】量化实习生（有留用机会）   \n",
       "22 2019-11-26     【实习】【上海】方正证券研究所金融工程组招聘量化实习生   \n",
       "23 2019-11-26                   【招聘】中国新闻出版研究院   \n",
       "24 2019-11-26   【实习】【北京】悟语学堂招聘传播/推广岗-坐标骏豪中央公园   \n",
       "25 2019-11-26               【微软】【北京】【实习】前端实习生   \n",
       "26 2019-11-26              【实习】【七鑫易维】 深度学习实习生   \n",
       "27 2019-11-26              【实习】【七鑫易维】 图像算法实习生   \n",
       "28 2019-11-26  【实习】【NVIDIA】英伟达2020实习季，期待你的加入！   \n",
       "29 2019-11-26               深圳Using.ai 招聘算法实习   \n",
       "30 2019-11-26                 【中国标准化研究院】招聘实习生   \n",
       "31 2019-11-26         【实习】【英特尔研究中心】计算机视觉/机器学习   \n",
       "32 2019-11-26            【兼职招聘】短视频视频剪辑 在校生也可以   \n",
       "33 2019-11-26              【百度实习】数据研发、数据挖掘工程师   \n",
       "34 2019-11-26                   【快手】【行政数据实习生】   \n",
       "35 2019-11-27                 【前海开源基金】人力资源实习生   \n",
       "36 2019-11-26              【快手】【公关实习生-数据分析方向】   \n",
       "37 2019-11-26             【快手】【公关实习生-短视频编辑方向】   \n",
       "38 2019-11-26         【实习】NLP算法、语音识别实习生【蓦然认知】   \n",
       "39 2019-11-26                   【快手】【部门助理实习生】   \n",
       "\n",
       "                                               detail category  \n",
       "20  岗位职责：  1.起草、审核合同及各类法律文件，制定标准合同文本，参与与合同相关的业务设计、...   券商投行基金  \n",
       "21  单位简介：  汇安基金管理有限责任公司，2016年4月19日获中国证监会批准，并在上海注册成...   券商投行基金  \n",
       "22  【实习】【上海】方正证券研究所金融工程组招聘量化实习生  【工作职责】  1、协助开发资产配...     量化交易  \n",
       "23    中国新闻出版研究院国际出版研究室  招聘小语种实习生    中国新闻出版研究院是我国唯一...      大数据  \n",
       "24  坐标：朝阳公园地铁边上骏豪中央公园  团队优势：弹性工作制、最火热最有价值的教育行业、行业大...     运营实习  \n",
       "25  热爱前端开发的同学，可以投简历过来yanhu@microsoft.com  表现出色可以争取...     研发开发  \n",
       "26   北京七鑫易维信息技术有限公司（www.7invensun.com）是致力于机器视觉和人工智...     算法实习  \n",
       "27   北京七鑫易维信息技术有限公司（www.7invensun.com）是致力于机器视觉和人工智...     算法实习  \n",
       "28  又是一年校招季的结束，当2020届的同学已经找到心仪工作的同时，2021届的同学们是否也蠢蠢...     研发开发  \n",
       "29  关于我们    贝尔信息是一家具备优秀且可商业化的机器学习、视觉技术和一体式硬件研发能力的高...     算法实习  \n",
       "30  中国标准化研究院（初名国家科委标准化综合研究所）始建于1963年，是从事标准化研究的国家  ...      大数据  \n",
       "31  简历请发送至：chenning.liu@intel.com          邮件标题：CV...     算法实习  \n",
       "32  【兼职招聘】短视频视频剪辑  会抖音小视频优先  自己或者朋友、亲戚家属，有擅长短视频制作的...     运营实习  \n",
       "33  团队介绍：拥有公司海量数据，专注于分析挖掘数据价值，通过数据平台和分析报告，助力产品线运营和...     研发开发  \n",
       "34  岗位职责：  1、负责协助行政项目的数据收集和整理；  2、负责对数据进行统计分析，根据数据...      大数据  \n",
       "35  【金牛基金公司-前海开源基金招聘】  岗位:人力资源实习生 base深圳  【岗位职责】  ...   券商投行基金  \n",
       "36  公关实习生-数据分析方向  岗位描述：  1、根据需求进行数据挖掘和分析；  2、兼具发散思...     数据分析  \n",
       "37  公关实习生-短视频编辑  职位描述：  1、负责快手用户故事的策划和制作；  2、热爱人物短...     运营实习  \n",
       "38  公司：北京蓦然认知科技有限公司  Base：北京  职位诱惑：AI独角兽潜力公司，薪资福利优...     算法实习  \n",
       "39  部门助理实习生  职位描述：  1、【部门事务支持】会议协调预定、办公用品管理、各类大小会议...       行政  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-guitar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
